{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clase10RP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOLLU1qguPP1e/IogUb319B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/germfsip/2132ReconocimientoPatrones/blob/main/Clase10RP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KsQ0t1NyMfO"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMGDLb4RyFfC"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1.0/(1.0 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivada(x):\n",
        "    return sigmoid(x)*(1.0-sigmoid(x))\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def tanh_derivada(x):\n",
        "    return 1.0 - x**2\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class RedNeuronal:\n",
        "\n",
        "    def __init__(self, layers, activation='tanh'):\n",
        "        if activation == 'sigmoid':\n",
        "            self.activation = sigmoid\n",
        "            self.activation_prime = sigmoid_derivada\n",
        "        elif activation == 'tanh':\n",
        "            self.activation = tanh\n",
        "            self.activation_prime = tanh_derivada\n",
        "\n",
        "        # inicializo los pesos\n",
        "        self.weights = []\n",
        "        self.deltas = []\n",
        "        # capas = [2,3,2]\n",
        "        # random de pesos varia entre (-1,1)\n",
        "        # asigno valores aleatorios a capa de entrada y capa oculta\n",
        "        for i in range(1, len(layers) - 1):\n",
        "            r = 2*np.random.random((layers[i-1] + 1, layers[i] + 1)) -1\n",
        "            self.weights.append(r)\n",
        "        # asigno aleatorios a capa de salida\n",
        "        r = 2*np.random.random( (layers[i] + 1, layers[i+1])) - 1\n",
        "        self.weights.append(r)\n",
        "\n",
        "    def fit(self, X, y, learning_rate=0.1, iteraciones=100000):\n",
        "        # Agrego columna de unos a las entradas X\n",
        "        # Con esto agregamos la unidad de Bias a la capa de entrada\n",
        "        ones = np.atleast_2d(np.ones(X.shape[0]))\n",
        "        X = np.concatenate((ones.T, X), axis=1)\n",
        "        \n",
        "        for k in range(iteraciones):\n",
        "            i = np.random.randint(X.shape[0])\n",
        "            a = [X[i]]\n",
        "\n",
        "            for l in range(len(self.weights)):\n",
        "                    dot_value = np.dot(a[l], self.weights[l])\n",
        "                    activation = self.activation(dot_value)\n",
        "                    a.append(activation)\n",
        "            # Calculo la diferencia en la capa de salida y el valor obtenido\n",
        "            error = y[i] - a[-1]\n",
        "            deltas = [error * self.activation_prime(a[-1])]\n",
        "            \n",
        "            # Empezamos en el segundo layer hasta el ultimo\n",
        "            # (Una capa anterior a la de salida)\n",
        "            for l in range(len(a) - 2, 0, -1): \n",
        "                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_prime(a[l]))\n",
        "            self.deltas.append(deltas)\n",
        "\n",
        "            # invertir\n",
        "            # [level3(output)->level2(hidden)]  => [level2(hidden)->level3(output)]\n",
        "            deltas.reverse()\n",
        "\n",
        "            # backpropagation\n",
        "            # 1. Multiplcar los delta de salida con las activaciones de entrada \n",
        "            #    para obtener el gradiente del peso.\n",
        "            # 2. actualizo el peso restandole un porcentaje del gradiente\n",
        "            for i in range(len(self.weights)):\n",
        "                layer = np.atleast_2d(a[i])\n",
        "                delta = np.atleast_2d(deltas[i])\n",
        "                self.weights[i] += learning_rate * layer.T.dot(delta)\n",
        "\n",
        "            if k % 10000 == 0: print('epochs:', k)\n",
        "\n",
        "    def predict(self, x): \n",
        "        ones = np.atleast_2d(np.ones(x.shape[0]))\n",
        "        a = np.concatenate((np.ones(1).T, np.array(x)), axis=0)\n",
        "        for l in range(0, len(self.weights)):\n",
        "            a = self.activation(np.dot(a, self.weights[l]))\n",
        "        return a\n",
        "\n",
        "    def print_weights(self):\n",
        "        print(\"LISTADO PESOS DE CONEXIONES\")\n",
        "        for i in range(len(self.weights)):\n",
        "            print(self.weights[i])\n",
        "\n",
        "    def get_deltas(self):\n",
        "        return self.deltas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKr717aayklF"
      },
      "source": [
        "Creamos Red neuronal para funci√≥n XOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-yX6LZ6ymcH",
        "outputId": "74e5d4b5-5c33-48f1-c9a7-3f378aa49715"
      },
      "source": [
        "# funcion XOR\n",
        "rn = RedNeuronal([2,2,1])\n",
        "X = np.array([[0, 0],\n",
        "            [0, 1],\n",
        "            [1, 0],\n",
        "            [1, 1]])\n",
        "y = np.array([0, 1, 1, 0])\n",
        "rn.fit(X, y,iteraciones=100000)\n",
        "for e in X:\n",
        "    print(\"Entradas:\",e,\"Salidas:\",rn.predict(e))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epochs: 0\n",
            "epochs: 10000\n",
            "epochs: 20000\n",
            "epochs: 30000\n",
            "epochs: 40000\n",
            "epochs: 50000\n",
            "epochs: 60000\n",
            "epochs: 70000\n",
            "epochs: 80000\n",
            "epochs: 90000\n",
            "Entradas: [0 0] Salidas: [1.19519481e-05]\n",
            "Entradas: [0 1] Salidas: [0.99365763]\n",
            "Entradas: [1 0] Salidas: [0.9955701]\n",
            "Entradas: [1 1] Salidas: [6.25512619e-05]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}